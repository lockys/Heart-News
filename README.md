# Heart-News 心聞
```
_    _                 _     _   _
| |  | |               | |   | \ | |
| |__| | ___  __ _ _ __| |_  |  \| | _____      _____
|  __  |/ _ \/ _` | '__| __| | . ` |/ _ \ \ /\ / / __|
| |  | |  __/ (_| | |  | |_  | |\  |  __/\ V  V /\__ \
|_|  |_|\___|\__,_|_|   \__| |_| \_|\___| \_/\_/ |___/


```
# Description
This site is a project of 2015 NTHU Cloud Programming.  
What we did is to collect ten thousand+ news' content in Taiwan and tranform them into many word segments (about 250 thousands+ words) using Amazon EMR service.  
After that, we will build a word cloud from those word segments based on a given time range.  
The more important word which may indiates what happend during that period will get bigger as you can see in the Screenshot. It may help users get to know what happened during a specific period.  
Users can also select a time range to see what happened during that period.

**The site is not available for now.**

# Screenshot
![Heart-News](/screenshot/1.png?raw=true "Heart-News")
![Heart-News](/screenshot/3.png?raw=true "Heart-News")
![Heart-News](/screenshot/2.png?raw=true "Heart-News")
![Heart-News](/screenshot/4.png?raw=true "Heart-News")

# Contributors
- [yuzzwx](https://github.com/yuzzwx)
- [lockys](https://github.com/lockys)
- [joy610189](https://github.com/joy610189)

# Future Work
Collect more news from past so that we can konw what happend in the past.

# Thanks
**文字雲 word cloud**  
[timdream/wordcloud2](https://github.com/timdream/wordcloud2.js)

**materialize framework**  
[Dogfalo/materialize](https://github.com/Dogfalo/materialize)  

**中文斷字 chinese word segmenter **  
[Stanford Word Segmenter](http://nlp.stanford.edu/software/segmenter.shtml)  

** backbone.js **  
[backbone.js](https://github.com/jashkenas/backbone)
